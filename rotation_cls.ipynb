{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SbxR_AUCrd2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06ae513-f421-45a4-b54c-e13fbd894fac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "archive = '/content/drive/MyDrive/datasets/rvl-cdip.zip'\n",
        "with zipfile.ZipFile(archive,\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/drive/MyDrive/datasets/rvl-cdip\")"
      ],
      "metadata": {
        "id": "YwMPu3ADNEJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OT7bwAFgVqIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886a7d2c-51b4-4a6c-a5a7-5888d75f2177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import cv2\n",
        "import datetime\n",
        "import fnmatch\n",
        "import glob\n",
        "from PIL import Image\n",
        "from skimage import io, transform\n",
        "from skimage.color import gray2rgb\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "imz0v2DUQd97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tVOrM4xwWzN7"
      },
      "outputs": [],
      "source": [
        "class DocDataset(Dataset):\n",
        "    def __init__(self, origin, classes, img_size, grayscale=False):\n",
        "        self.items = []\n",
        "        self.gt = []\n",
        "\n",
        "        if os.path.exists(origin):\n",
        "            self.origin = origin\n",
        "            self.img_size = img_size\n",
        "            self.grayscale = grayscale\n",
        "            self.classes = np.array(classes)\n",
        "            \n",
        "            for cls_id, cls_name in enumerate(self.classes):                \n",
        "                cls_path = os.path.join(origin, cls_name)\n",
        "                if os.path.exists(cls_path) and os.path.isdir(cls_path):\n",
        "                    # get items\n",
        "                    files = glob.glob(f\"{cls_path}/*\")\n",
        "                    self.items.extend(files)\n",
        "                    self.gt.extend([cls_id] * len(files))\n",
        "            \n",
        "            self.gt = torch.tensor(self.gt, dtype=torch.int64)\n",
        "            self.items = np.array(self.items)\n",
        "            self.loaded = True\n",
        "        else:\n",
        "            self.loaded = False\n",
        "\n",
        "    @staticmethod\n",
        "    def img_path_to_input(image_path, img_size, grayscale):\n",
        "        \"\"\"\n",
        "        loads image from file and transforms it to tensor of required size\n",
        "        \"\"\"\n",
        "        image = io.imread(image_path, as_gray=False)\n",
        "        image = cv2.resize(image, dsize=(img_size,img_size), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        if not grayscale:\n",
        "            image = gray2rgb(image)\n",
        "            image = image.transpose((2, 0, 1))\n",
        "\n",
        "        image = torch.from_numpy(image)\n",
        "        image = image / 255.\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        # get item info\n",
        "        image_path = self.items[idx]\n",
        "        gt = self.gt[idx]\n",
        "        # load and preprocess image\n",
        "        image = DocDataset.img_path_to_input(image_path, self.img_size, self.grayscale)\n",
        "        return image, gt, torch.tensor(idx, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion matrix"
      ],
      "metadata": {
        "id": "0tvdBd3PQgrn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nc1S5sdMrToT"
      },
      "outputs": [],
      "source": [
        "def print_confusion_matrix(gt, pred, class_names):\n",
        "    cf_matrix = confusion_matrix(gt, pred)\n",
        "    dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
        "\n",
        "    plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
        "\n",
        "    plt.ylabel(\"True Class\"), \n",
        "    plt.xlabel(\"Predicted Class\")\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "def save_confusion_matrix(gt, pred, class_names, file):\n",
        "    cf_matrix = confusion_matrix(gt, pred)\n",
        "    dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
        "\n",
        "    plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
        "\n",
        "    plt.ylabel(\"True Class\"), \n",
        "    plt.xlabel(\"Predicted Class\")\n",
        "    plt.savefig(file)\n",
        "    plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Z8jTBG3VQbmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.bn1.momentum = 0.1\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.bn2.momentum = 0.1\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes, grayscale):\n",
        "        self.inplanes = 64\n",
        "        if grayscale:\n",
        "            in_dim = 1\n",
        "        else:\n",
        "            in_dim = 3\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn1.momentum = 0.1\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, track_running_stats=False),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)        \n",
        "        x = self.avgpool(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.fc(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "\n",
        "\n",
        "\n",
        "def ResNet18(num_classes, grayscale):\n",
        "    model = ResNet(block=BasicBlock, \n",
        "                   layers=[2, 2, 2, 2],\n",
        "                   num_classes=num_classes,\n",
        "                   grayscale=grayscale)\n",
        "    return model"
      ],
      "metadata": {
        "id": "OvEDpqQFEPmF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINER - dataloaders, train, eval, predict methods"
      ],
      "metadata": {
        "id": "bfnD5MgOQndW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, device, classes, img_size=224, grayscale=False, experiments_dir=None, verbose=True):\n",
        "        self.img_size = img_size\n",
        "        self.grayscale = grayscale\n",
        "        self.device = device\n",
        "        self.classes = np.array(classes)\n",
        "        self.experiments_dir = experiments_dir\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.trainloader_rdy = False\n",
        "        self.valloader_rdy = False\n",
        "        self.model_rdy = False\n",
        "\n",
        "\n",
        "    def setup_loaders_with_split(self, set_origin, batch_size, validation_split=.2, shuffle=True):\n",
        "        ds = DocDataset(set_origin, self.classes, self.img_size, self.grayscale)\n",
        "        if shuffle:\n",
        "            indices = torch.randperm(len(ds))\n",
        "        else:\n",
        "            indices = list(range(len(ds)))\n",
        "\n",
        "        # split train/eval\n",
        "        split = int(np.floor(validation_split * len(indices)))\n",
        "        train_indices, val_indices = indices[split:], indices[:split]\n",
        "        # sampler\n",
        "        train_sampler = SubsetRandomSampler(train_indices)\n",
        "        val_sampler = SubsetRandomSampler(val_indices)\n",
        "        # loaders\n",
        "        self.train_loader = DataLoader(ds, batch_size=batch_size, sampler=train_sampler)\n",
        "        self.val_loader = DataLoader(ds, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "        self.trainloader_rdy = True\n",
        "        self.valloader_rdy = True\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"Train and Validation loaders created\")\n",
        "\n",
        "\n",
        "    def setup_train_loader(self, trainset_origin, batch_size, shuffle=True):\n",
        "        trainset = DocDataset(trainset_origin, self.classes, self.img_size, self.grayscale)\n",
        "        self.train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=shuffle)\n",
        "        self.trainloader_rdy = True\n",
        "        if self.verbose:\n",
        "            print(\"Train loader created\")\n",
        "\n",
        "\n",
        "    def setup_val_loader(self, valset_origin, batch_size, shuffle=True):\n",
        "        valset = DocDataset(valset_origin, self.classes, self.img_size, self.grayscale)\n",
        "        self.val_loader = DataLoader(valset, batch_size=batch_size, shuffle=shuffle)\n",
        "        self.valloader_rdy = True\n",
        "        if self.verbose:\n",
        "            print(\"Validation loader created\")\n",
        "\n",
        "\n",
        "    def init_model(self, load_state_dict=None):\n",
        "        self.model = ResNet18(len(self.classes), self.grayscale)\n",
        "        if self.verbose:\n",
        "            print(\"Model initialized\")\n",
        "\n",
        "        if load_state_dict is not None and os.path.exists(load_state_dict):\n",
        "            # load pretrained weights if given\n",
        "            self.model.load_state_dict(torch.load(load_state_dict, map_location=self.device))\n",
        "            if self.verbose:\n",
        "                print(\"Model state dict loaded\")\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        self.model_rdy = True\n",
        "\n",
        "\n",
        "    def train(self, epochs, eval_each=None, log=False, show_confusion_matrices=False, save_best_model=False):        \n",
        "        if not self.trainloader_rdy:\n",
        "            print(\"Train loader not created\")\n",
        "            return False\n",
        "        if not self.valloader_rdy and eval_each is not None:\n",
        "            print(\"Validation loader not created\")\n",
        "            return False\n",
        "        if save_best_model and self.experiments_dir is None:\n",
        "            print(\"Requested model save, but experiments dir not specified\")\n",
        "            return False\n",
        "        if log and self.experiments_dir is None:\n",
        "            print(\"Requested logging, but experiments dir not specified\")\n",
        "            return False\n",
        "        if log and not os.path.exists(self.experiments_dir):\n",
        "            print(\"Logging requested, but experiments directory does not exists\")\n",
        "            return False\n",
        "        if not self.model_rdy:\n",
        "            print(\"Model not initialized\")        \n",
        "            return False\n",
        "\n",
        "        print(\"Training\")\n",
        "\n",
        "        # logging experiment setting\n",
        "        logdir = None\n",
        "        if log:\n",
        "            # log directory init\n",
        "            now = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
        "            logdir_name = 'start_' + now\n",
        "            logdir = os.path.join(self.experiments_dir, logdir_name)\n",
        "            os.mkdir(logdir)                    \n",
        "            print(f\" LOGGING EXPERIMENT to: {logdir}\")\n",
        "\n",
        "            # logfile init\n",
        "            trainstats_file = os.path.join(logdir, \"stats.csv\")\n",
        "            with open(trainstats_file, \"a\") as fd:\n",
        "                fd.write(\"epoch,loss,loss_avg,train_acc,eval_acc\\n\")            \n",
        "            \n",
        "\n",
        "        # training settings\n",
        "        self.model.train()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=3e-3)\n",
        "        \n",
        "        # stats accumulator\n",
        "        stats = pd.DataFrame({\n",
        "            'epoch': [],\n",
        "            'loss': [],\n",
        "            'loss_avg': [],\n",
        "            'train_acc': [],\n",
        "            'eval_acc': []\n",
        "        })        \n",
        "        best_eval_acc = 0\n",
        "\n",
        "        # TRAIN LOOP\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            epoch_loss, epoch_hits, epoch_samples = 0, 0, 0\n",
        "            for i, data in tqdm(enumerate(self.train_loader), total=len(self.train_loader)):\n",
        "                # input\n",
        "                input, gt, idx = data\n",
        "                input = input.to(self.device)\n",
        "                gt = gt.to(self.device)\n",
        "                                  \n",
        "                # forward & backward pass & GD\n",
        "                optimizer.zero_grad()\n",
        "                output_logits, output_probs = self.model(input)\n",
        "                    \n",
        "\n",
        "                loss = F.cross_entropy(output_logits, gt.type(torch.long))                               \n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # batch train stats\n",
        "                pred = torch.argmax(output_logits, axis=1)\n",
        "                hits = (gt == pred).sum()\n",
        "                epoch_hits += hits.item()\n",
        "                epoch_samples += pred.shape[0]                \n",
        "                epoch_loss += loss.item()                                                \n",
        "            \n",
        "            # epoch train stats\n",
        "            epoch_loss_avg = epoch_loss / (len(self.train_loader) * self.train_loader.batch_size)\n",
        "            train_acc = epoch_hits / epoch_samples * 100\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\" Epoch: {epoch}, loss = {epoch_loss}, loss_avg = {epoch_loss_avg}, train accuracy: {train_acc}%\")\n",
        "\n",
        "            # evaluation during training\n",
        "            eval_acc = -1\n",
        "            if eval_each is not None and (epoch+1) % eval_each == 0:\n",
        "                # evaluation\n",
        "                eval_acc, eval_stats = self._eval(False)\n",
        "                                \n",
        "                if show_confusion_matrices:\n",
        "                    print_confusion_matrix(eval_stats['gt'].tolist(), eval_stats['pred'].tolist(), self.classes)\n",
        "\n",
        "                # if best so far - log and save state dict\n",
        "                if eval_acc > best_eval_acc:\n",
        "                    best_eval_acc = eval_acc\n",
        "\n",
        "                    if save_best_model:\n",
        "                        torch.save(self.model.state_dict(), os.path.join(logdir, f\"bestmodel.pth\"))\n",
        "                        save_confusion_matrix(eval_stats['gt'].tolist(), eval_stats['pred'].tolist(), self.classes, os.path.join(logdir, 'best_cfm.png'))\n",
        "                        \n",
        "                        bestmodel_acc_file = os.path.join(logdir, 'bestmodel_stats.csv')\n",
        "                        with open(bestmodel_acc_file, \"w\") as fd:\n",
        "                            fd.write(\"epoch,loss,loss_avg,train_acc,eval_acc\\n\")\n",
        "                            fd.write(f\"{epoch},{epoch_loss},{epoch_loss_avg},{train_acc},{eval_acc}\\n\")\n",
        "\n",
        "            batch_stats = pd.DataFrame({\n",
        "                'epoch': [epoch],\n",
        "                'loss': [epoch_loss],\n",
        "                'loss_avg': [epoch_loss_avg],\n",
        "                'train_acc': [train_acc],\n",
        "                'eval_acc': [eval_acc]\n",
        "            })\n",
        "            stats = pd.concat([stats, batch_stats], ignore_index=True)\n",
        "            stats.reset_index()\n",
        "\n",
        "            # epoch stats log\n",
        "            with open(trainstats_file, \"a\") as fd:\n",
        "                log_eval_acc = eval_acc\n",
        "                if log_eval_acc == -1:\n",
        "                    log_eval_acc = \"\"\n",
        "                fd.write(f\"{epoch},{epoch_loss},{epoch_loss_avg},{train_acc},{log_eval_acc}\\n\")   \n",
        "\n",
        "\n",
        "        \n",
        "        # plot epochs average loss evolution\n",
        "        if log or self.verbose:\n",
        "            sns.lineplot(data=stats['loss_avg'].tolist(), palette='YlGnBu')\n",
        "            plt.title('Avg training loss')\n",
        "            if log:\n",
        "                loss_logfile = os.path.join(logdir, 'loss_evo.png')\n",
        "                plt.savefig(loss_logfile)\n",
        "            if self.verbose:\n",
        "                plt.show()\n",
        "            plt.clf()\n",
        "\n",
        "        # plot epochs evaluation accuracy evolution            \n",
        "        if log or self.verbose:\n",
        "            plt.plot(stats['epoch'], stats['train_acc'], marker='.', color='r', label= 'training accuracy')\n",
        "            \n",
        "            valid_eval_accs = [eval_acc for eval_acc in stats['eval_acc'].tolist() if eval_acc != -1]\n",
        "            valid_eval_epochs = [epoch for epoch, eval_acc in zip(stats['epoch'].tolist(), stats['eval_acc'].tolist()) if eval_acc != -1]\n",
        "            plt.plot(valid_eval_epochs, valid_eval_accs, marker = '+', color = 'g',label = 'evaluation accuracy')\n",
        "\n",
        "            plt.legend()\n",
        "            plt.title('Training and evaluation accuracy evolution')\n",
        "            if log:\n",
        "                acc_logfile = os.path.join(logdir, 'acc_evo.png')\n",
        "                plt.savefig(acc_logfile)\n",
        "            if self.verbose:\n",
        "                plt.show()            \n",
        "            plt.clf()\n",
        "    \n",
        "    def _eval(self, filestats_stdout=False):\n",
        "        print(\"Evaluation\")\n",
        "        # self.model.eval()\n",
        "            \n",
        "        # stats accumulators\n",
        "        hits_count, samples_count = 0, 0\n",
        "        stats = {\n",
        "            'filename': [],\n",
        "            'gt': [],\n",
        "            'pred': [],\n",
        "            'certainty': [],\n",
        "            'error': []\n",
        "        }\n",
        "\n",
        "        # EVAL LOOP\n",
        "        for i, data in tqdm(enumerate(self.val_loader), total=len(self.val_loader)):\n",
        "            # inputs\n",
        "            input, gt, idx = data\n",
        "            input = input.to(self.device)\n",
        "            gt = gt.to(self.device)\n",
        "            \n",
        "            # forward pass\n",
        "            output_logits, output_probs = self.model(input)\n",
        "\n",
        "            # predictions & stats\n",
        "            pred = torch.argmax(output_logits, axis=1)\n",
        "            certainty = torch.max(output_probs, axis=1).values\n",
        "            err = (gt != pred)\n",
        "            hits = (gt == pred).sum()\n",
        "            \n",
        "            hits_count += hits.item()\n",
        "            samples_count += pred.shape[0]\n",
        "\n",
        "            stats['filename'].extend(self.val_loader.dataset.items[idx.tolist()])\n",
        "            stats['gt'].extend(self.classes[gt.tolist()])\n",
        "            stats['pred'].extend(self.classes[pred.tolist()])\n",
        "            stats['certainty'].extend(certainty.tolist())\n",
        "            stats['error'].extend(err.tolist())\n",
        "\n",
        "            if filestats_stdout:\n",
        "                for i in range(pred.shape[0]):\n",
        "                    file_error_symbol = '+'\n",
        "                    if err[i]:\n",
        "                        file_error_symbol = '-'\n",
        "                    print(f\"{file_error_symbol} | {self.val_loader.dataset.items[idx[i]]}: gt={self.classes[gt[i]]}, pred={self.classes[pred[i]]}, certainty={certainty[i]:.3f}\")\n",
        "\n",
        "        stats = pd.DataFrame(stats)            \n",
        "                    \n",
        "        acc = 0\n",
        "        if samples_count != 0:\n",
        "            acc = hits_count / samples_count * 100\n",
        "            \n",
        "        if self.verbose:\n",
        "            print(f\" Validation accuracy: {acc}%\")\n",
        "    \n",
        "        return acc, stats\n",
        "\n",
        "    def evaluate(self, show_confusion_matrix=True, filestats_stdout=False, logdir=None):\n",
        "        acc, stats = self._eval(filestats_stdout)\n",
        "        \n",
        "        if logdir is not None:\n",
        "            if not os.path.exists(logdir):\n",
        "                os.mkdir(logdir)            \n",
        "            \n",
        "            filestats_path = os.path.join(logdir, 'filestats.csv')\n",
        "            stats.to_csv(filestats_path)\n",
        "            \n",
        "            acc_path = os.path.join(logdir, 'accuracy.txt')\n",
        "            with open(acc_path, \"w\") as fd:\n",
        "                fd.write(f\"Accuracy: {acc}%\")\n",
        "\n",
        "            cfm_path = os.path.join(logdir, 'cfm.png')\n",
        "            save_confusion_matrix(stats['gt'].tolist(), stats['pred'].tolist(), self.classes, cfm_path)\n",
        "\n",
        "        if show_confusion_matrix:\n",
        "            print_confusion_matrix(stats['gt'].tolist(), stats['pred'].tolist(), self.classes)\n",
        "\n",
        "        return acc, stats\n",
        "\n",
        "    def predict(self, file_or_folder, batch_size=1, print_results=True, results_file=None, plot=True):\n",
        "        if not self.model_rdy:\n",
        "            print(\"Model not initialized\")        \n",
        "            return False\n",
        "        if not os.path.exists(file_or_folder):\n",
        "            print(\"source for prediction not found\")\n",
        "\n",
        "        print(\"Resolving samples\")\n",
        "\n",
        "        files = []\n",
        "        if os.path.isfile(file_or_folder):\n",
        "            files = [file_or_folder]\n",
        "        else:            \n",
        "            for (dir_path, dir_names, file_names) in os.walk(file_or_folder):\n",
        "                files.extend(file_names)\n",
        "            p = Path(file_or_folder).glob('**/*')\n",
        "            files = [x.as_posix() for x in p if x.is_file()]\n",
        "        print(f\" {len(files)} items found\")    \n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        # init results file\n",
        "        if results_file is not None:\n",
        "            with open(results_file, \"w\") as fd:\n",
        "                fd.write(f\"filename, pred, certainty\\n\")\n",
        "        \n",
        "        results = []\n",
        "\n",
        "        print(\"Prediction\")\n",
        "\n",
        "        batched_files = [files[i:i + batch_size] for i in range(0, len(files), batch_size)]\n",
        "        for batch in batched_files:\n",
        "            images = []\n",
        "            for file in batch:\n",
        "                images.append(DocDataset.img_path_to_input(file, self.img_size, self.grayscale))\n",
        "            input = torch.stack(images, dim=0)\n",
        "\n",
        "            input = input.to(self.device)\n",
        "            output_logits, output_probs = self.model(input)\n",
        "        \n",
        "            pred = torch.argmax(output_logits, axis=1)\n",
        "            certainty = torch.max(output_probs, axis=1).values\n",
        "            class_names = self.classes[pred.tolist()]\n",
        "\n",
        "            results.extend(zip(batch, class_names))\n",
        "\n",
        "            # plot \n",
        "            if plot:\n",
        "                plt.figure(figsize=(30,30))\n",
        "                for i in range(len(images)):\n",
        "                    plt.subplot(5,5,i+1).set_title(class_names[i] + \" (\" + str(round(certainty[i].item()*100,2)) + \"%)\")\n",
        "                    plt.imshow(images[i].permute((1,2,0)))\n",
        "                plt.show()\n",
        "\n",
        "            # print\n",
        "            if print_results:\n",
        "                for i in range(len(batch)):\n",
        "                    filename = os.path.basename(batch[i])\n",
        "                    print(f\"{filename}, {class_names[i]}, {certainty[i]}\\n\")\n",
        "\n",
        "            # save results to file\n",
        "            if results_file is not None:\n",
        "                with open(results_file, \"a\") as fd:\n",
        "                    for i in range(len(batch)):\n",
        "                        filename = os.path.basename(batch[i])\n",
        "                        fd.write(f\"{filename}, {class_names[i]}, {certainty[i]}\\n\")\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "T7Ui_sjjC48Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN"
      ],
      "metadata": {
        "id": "FjeK7Q4dRWnC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwJdXHFUmOBR",
        "outputId": "992d44db-606f-4bed-f37c-ffdd69233030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on GPU\n"
          ]
        }
      ],
      "source": [
        "if(torch.cuda.is_available()):\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"running on GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"running on CPU\")\n",
        "\n",
        "trainer = Trainer(\n",
        "     device = device, \n",
        "     classes = ['up', 'down', 'left', 'right'], \n",
        "     img_size=224, \n",
        "     grayscale=False, \n",
        "     experiments_dir='/content/drive/MyDrive/DS/rotation_cls/runs', \n",
        "     verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.init_model()\n",
        "trainer.init_model(load_state_dict='/content/drive/MyDrive/DS/rotation_cls/runs/start_20221120T220134/bestmodel.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zJkw9dIYatZ",
        "outputId": "15cbf1e9-fd0a-444c-cec3-a50993e73696"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.setup_loaders_with_split( \n",
        "    set_origin = '/content/drive/MyDrive/datasets/test',\n",
        "    batch_size = 8,\n",
        "    validation_split = .2, \n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwovuYqrYWr-",
        "outputId": "215e9278-966e-44fc-df59-39e3f47e81de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Validation loaders created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.setup_train_loader(\n",
        "    trainset_origin = '/content/drive/MyDrive/DS/rotation_cls/rvl-cdip/train_sampled_anglesplit', \n",
        "    batch_size = 16,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "trainer.setup_val_loader(\n",
        "    valset_origin = '/content/drive/MyDrive/DS/rotation_cls/rvl-cdip/test_sampled_anglesplit', \n",
        "    batch_size = 8, \n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "id": "fTOFfPbmYWxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(\n",
        "    epochs = 20,\n",
        "    eval_each = 1, \n",
        "    log = True, \n",
        "    show_confusion_matrices = True,\n",
        "    save_best_model = True\n",
        ")"
      ],
      "metadata": {
        "id": "mDn0B3lVwwh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc, stats = trainer.evaluate(\n",
        "    show_confusion_matrix=True, \n",
        "    filestats_stdout=False, \n",
        "    logdir='/content/log'\n",
        ")"
      ],
      "metadata": {
        "id": "f--cLuNLVE1M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599,
          "referenced_widgets": [
            "8e5f7fe86c8b43e889db20695db86827",
            "be39758a86d84377b56446f61f8ffbfc",
            "d9812c8179db40b1b541d4f04a5cc156",
            "5ecb4589fa9e4c1ab80932729d22d0d3",
            "bc8fe322dd424173b9eae1b95adc71c7",
            "74610823a1d543ce800f2d839a51ccd1",
            "c86ddc0d3f0648d1b0dd64764537338e",
            "367c48f0432747f2994d7a2dd6f4a983",
            "297c6b6173034529b456a4c74220fad7",
            "9486e0364daf47c09a27d01e62eef9ab",
            "3fc5ffe8f3b84fd58ab5a7405606b410"
          ]
        },
        "outputId": "279120c3-eb62-4e6a-cbd2-4eb3d3f97134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/132 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e5f7fe86c8b43e889db20695db86827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Validation accuracy: 25.0%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(\n",
        "    file_or_folder = '/content/drive/MyDrive/DS/rotation_cls/pred_test', \n",
        "    batch_size=16, \n",
        "    print_results=True, \n",
        "    results_file='/content/log/tst.csv', \n",
        "    plot=True\n",
        ")"
      ],
      "metadata": {
        "id": "4E7LJqxIscJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uW3aSvTmd8tX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e5f7fe86c8b43e889db20695db86827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be39758a86d84377b56446f61f8ffbfc",
              "IPY_MODEL_d9812c8179db40b1b541d4f04a5cc156",
              "IPY_MODEL_5ecb4589fa9e4c1ab80932729d22d0d3"
            ],
            "layout": "IPY_MODEL_bc8fe322dd424173b9eae1b95adc71c7"
          }
        },
        "be39758a86d84377b56446f61f8ffbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74610823a1d543ce800f2d839a51ccd1",
            "placeholder": "",
            "style": "IPY_MODEL_c86ddc0d3f0648d1b0dd64764537338e",
            "value": "100%"
          }
        },
        "d9812c8179db40b1b541d4f04a5cc156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367c48f0432747f2994d7a2dd6f4a983",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_297c6b6173034529b456a4c74220fad7",
            "value": 132
          }
        },
        "5ecb4589fa9e4c1ab80932729d22d0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9486e0364daf47c09a27d01e62eef9ab",
            "placeholder": "",
            "style": "IPY_MODEL_3fc5ffe8f3b84fd58ab5a7405606b410",
            "value": " 132/132 [00:35&lt;00:00,  4.60it/s]"
          }
        },
        "bc8fe322dd424173b9eae1b95adc71c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74610823a1d543ce800f2d839a51ccd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86ddc0d3f0648d1b0dd64764537338e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "367c48f0432747f2994d7a2dd6f4a983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297c6b6173034529b456a4c74220fad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9486e0364daf47c09a27d01e62eef9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fc5ffe8f3b84fd58ab5a7405606b410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}